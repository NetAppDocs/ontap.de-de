---
permalink: fabricpool/move-volume-task.html 
sidebar: sidebar 
keywords: aggregate, local tier, moving, volume, fabricpool, fabric pool, tiering, policy, policies, block, capacity, cold data, 
summary: 'Es ist wichtig zu wissen, wie die Volume-Verschiebung mit FabricPool funktioniert, da die Änderungen, die sowohl auf der lokalen Tier, der Attached Cloud-Ebene als auch auf dem Volume (Volume-Tiering-Richtlinien) stattfinden, große Auswirkungen auf die Funktionalität haben können.' 
---
= Verschieben Sie ein Volume auf eine lokale ONTAP-Tier mit FabricPool-Unterstützung
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Unter anderem link:../volumes/move-volume-task.html["Volume-Verschiebung"]verschiebt ONTAP ein Volume unterbrechungsfrei von einer lokalen Tier (Quelle) zu einem anderen (Ziel). Volume-Verschiebungen sind aus verschiedenen Gründen möglich, wenngleich die häufigsten Gründe dafür Hardware Lifecycle Management, Cluster-Erweiterung und Lastausgleich sind.

Es ist wichtig zu wissen, wie die Volume-Verschiebung mit FabricPool funktioniert, da die Änderungen, die sowohl auf der lokalen Tier, der Attached Cloud-Ebene als auch auf dem Volume (Volume-Tiering-Richtlinien) stattfinden, große Auswirkungen auf die Funktionalität haben können.


NOTE: Vor ONTAP 9.7 verwendet System Manager den Begriff „_Aggregate_“, um eine „_Local Tier_“ zu beschreiben. Unabhängig von Ihrer ONTAP-Version verwendet die ONTAP CLI den Begriff _Aggregate_. Weitere Informationen zu lokalen Ebenen finden Sie unter link:../disks-aggregates/index.html["Festplatten und lokale Tiers"].



== Lokale Ebene des Ziels

Verfügt die lokale Ziel-Tier einer Volume-Verschiebung nicht über eine verbundene Cloud-Tier, werden die Daten des in der Cloud-Tier gespeicherten Quell-Volumes in die lokale Tier der lokalen Ziel-Tier geschrieben.

Ab ONTAP 9.8 verwendet FabricPool, wenn ein Volume link:determine-data-inactive-reporting-task.html["Berichterstellung für inaktive Daten"]aktiviert ist, die Heatmap des Volumes, um kalte Daten sofort in die Warteschlange einzureihen, um mit dem Tiering zu beginnen, sobald sie auf die lokale Ziel-Tier geschrieben werden.

Vor ONTAP 9.8 wird durch das Verschieben eines Volumes auf eine andere lokale Tier die Inaktivitätsdauer von Blöcken auf der lokalen Tier zurückgesetzt. Ein Volume mit der Tiering-Richtlinie für automatisches Volume mit Daten auf der lokalen Tier, das 20 Tage inaktiv, aber noch nicht gestaffelt war, hat beispielsweise die Temperatur der Daten nach einer Volume-Verschiebung auf 0 Tage zurückgesetzt.



== Optimierte Verschiebung von Volumes

Ab ONTAP 9.6 werden die Daten des im Bucket gespeicherten Quell-Volume nicht zurück auf die lokale Tier verschoben, wenn die lokale Ziel-Tier einer Volume-Verschiebung denselben Bucket verwendet. Tiering-Daten bleiben im Ruhezustand, und nur heiße Daten müssen von einer lokalen Tier in eine andere verschoben werden. Diese optimierte Volume-Verschiebung führt zu einer erheblichen Netzwerkeffizienz.

Nicht optimierte Volume-Verschiebungen generieren zusätzlichen Netzwerk- und Computing-Datenverkehr (Lese-/Schreibvorgänge und Schreibvorgänge/Puts). Dadurch steigen die Anforderungen an das ONTAP-Cluster und den Objektspeicher, was möglicherweise die Kosten durch Tiering auf öffentliche Objektspeicher in die Höhe treibt.

[NOTE]
====
Einige Konfigurationen sind nicht mit optimierten Volume-Verschiebungen kompatibel:

* Tiering-Richtlinie wird während der Volume-Verschiebung geändert
* Lokale Quell- und Ziel-Tiers mit unterschiedlichen Verschlüsselungsschlüsseln
* FlexClone Volumes
* Übergeordnete FlexClone Volumes
* MetroCluster (unterstützt optimierte Volume-Verschiebungen in ONTAP 9.8 und höher)
* Nicht synchronisierte FabricPool Mirror Buckets


====
Verfügt die lokale Tier einer Volume-Verschiebung über eine angeschlossene Cloud-Tier, werden die Daten des auf der Cloud-Tier gespeicherten Quell-Volumes zuerst auf die lokale Tier auf der lokalen Ziel-Tier geschrieben. Anschließend wird in die Cloud-Tier auf der lokalen Ziel-Tier geschrieben, sofern dieser Ansatz für die Tiering-Richtlinie des Volumes geeignet ist.

Durch das Schreiben von Daten in die lokale Tier wird zunächst die Performance der Volume-Verschiebung verbessert und die Umstellungszeit verkürzt. Wird bei der Verschiebung eines Volumes keine Tiering-Richtlinie angegeben, verwendet das Ziel-Volume die Tiering-Richtlinie des Quell-Volume.

Wird bei der Volume-Verschiebung eine andere Tiering-Richtlinie angegeben, wird das Ziel-Volume mit der angegebenen Tiering-Richtlinie erstellt und die Volume-Verschiebung nicht optimiert.



=== Volume-Metadaten

Unabhängig davon, ob eine Volume-Verschiebung optimiert wird, speichert ONTAP Informationen über den Speicherort aller Daten, einschließlich lokaler und Tiering-Daten. Wenn ein Volume von einer lokalen Ebene auf eine andere verschoben wird, muss diese Information ebenfalls in die lokale Ziel-Tier verschoben werden. Diese Metadaten bleiben immer auf der lokalen Tier, doch kann dies je nach Menge der Tiering-Daten dazu führen, dass der Volume-Verschiebungsprozess mehr dauert als erwartet.

Ein Beispiel ist die optimierte Verschiebung von Volumes mit 300 TB. Das bedeutet, dass 300 TB weniger kalte Daten nicht von einer lokalen Tier zu einer anderen verschoben werden müssen (oder 300 TB Lesezugriffe und 300 TB Schreibvorgänge in den Objektspeicher auslösen). Es bedeutet aber, dass die mit 300 TB an Daten verbundenen Metadaten (~15 TB an Daten in diesem Beispiel) auf die lokale Ziel-Tier geschrieben werden müssen.

Es ist wichtig zu wissen, dass der durch den Befehl angegebene „Durchsatz“ `volume move show` keinen Durchsatz im Hinblick auf die Daten darstellt, die aus der Cloud-Tier verschoben werden, sondern dass die Metadaten lokal aktualisiert werden.


NOTE: In einer SVM-DR-Beziehung müssen Quell- und Ziel-Volumes dieselbe Tiering-Richtlinie verwenden.

.Schritte
. Verwenden Sie den `volume move start` Befehl, um ein Volume von einer lokalen Quell-Tier auf eine lokale Ziel-Tier zu verschieben.


.Beispiel für das Verschieben eines Volumes
Im folgenden Beispiel wird ein Volume mit dem Namen `vs1` SVM in `dest_FabricPool` eine lokale Tier mit FabricPool-Aktivierung verschoben `myvol2`.

[listing]
----
cluster1::> volume move start -vserver vs1 -volume myvol2
-destination-aggregate dest_FabricPool
----